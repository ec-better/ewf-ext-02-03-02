{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## ewf-ext-02-03-02 - NDVI growing season statistics time series per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDVI growing season statistics time series per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'NDVI growing season statistics time series per pixel'),\n",
    "                ('abstract', 'NDVI growing season statistics time series per pixel'),\n",
    "                ('id', 'ewf-ext-02-03-02')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON ((-8.864205 38.88616500000001, -8.864205 38.986165, -8.964205000000002 38.986165, -8.964205000000002 38.88616500000001, -8.864205 38.88616500000001))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfRegion = dict([('id', 'nameOfRegion'),\n",
    "                     ('value', 'P001'),\n",
    "                     ('title', 'Name of Region'),\n",
    "                     ('abstract', 'Name of the region of interest'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndviIndex = dict([('id', 'ndviIndex'),\n",
    "             ('value', 'better-ext-02-03-01'),\n",
    "             ('title', 'ndvi catalog index'),\n",
    "             ('abstract', 'index to access ndvi catalog'),\n",
    "             ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndviApikey = dict([('id', 'ndviApikey'),\n",
    "                ('value', ''),\n",
    "                ('title', 'ndvi catalog apikey'),\n",
    "                ('abstract', 'apikey to access ndvi catalog'),\n",
    "                ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the NDVI stack of products' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2014\n",
    "#input_identifiers = ('LE07_L1TP_204033_20140311_20161117_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20140428_20161116_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20140514_20161115_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20140530_20161115_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20140615_20161113_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20140701_20161112_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20140717_20161112_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20140818_20161111_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20141208_20161030_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20141224_20161030_01_T1_sr_P001_NDVI.tif')\n",
    "\n",
    "# 2015\n",
    "#input_identifiers = ('LE07_L1TP_204033_20150109_20161030_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20150125_20161029_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20150314_20161028_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20150330_20161028_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20150517_20161026_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20150602_20161025_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20150618_20161025_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20150704_20161024_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20150720_20161027_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20150805_20161023_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20150821_20161022_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20150922_20161019_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20151008_20161018_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20151109_20161017_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20151227_20161016_01_T1_sr_P001_NDVI.tif')\n",
    "\n",
    "#input_identifiers = ('0CFC36158132DA794782B428E6DF76E7DC4C07CD', '4F49AF0E4B772965258B1AD001423D60228BB49A', '82A433CFFE0F4115F8A4BBFFDCB1C3D6A5709427', '487C80B2EF22D66AB8F10F65A7CBD6BAFB3E3939', '87E43FB9A02BE617A7A731DDD668B661B6EBCE07', '03F1348D9DCDC9A1E1A2B544E76C92420E70A31A', 'C72F7439E9A8853E8D64B44E52A0D24CF797F6E6', '164BB5EE04E403530B3C87F0ECDF4E95C54188B8', '1E44F63186475D883CDB9FED5E2ACB8CA992A9DF', '01D316DE31BAD714AF0F9B0CFCEED5E7697BC09F', '0E314958DD97CF88FF11F81147CE52AF3FD13B4A', 'C812DC63D58400C16515C79F8C4BCA32332B2724', 'B8EF89460AF0FE1344881FBEF5E533371BD6C404', 'A27CAA804DDA8A3B9256D1E4B9E080031E6BEBCD', '2DA8C200ABE9599DD7D5BDB155B0BE1922E2F139')\n",
    "\n",
    "# 2016\n",
    "##input_identifiers = ('LE07_L1TP_204033_20160112_20161015_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20160229_20161014_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20160401_20161013_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20160503_20161011_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20160519_20161010_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20160620_20161209_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20160706_20161009_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20160722_20161010_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20160807_20161008_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20160823_20161007_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20160908_20161006_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20160924_20161023_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20161026_20161121_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20161127_20170118_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20161229_20170219_01_T1_sr_P001_NDVI.tif')\n",
    "\n",
    "#input_identifiers = ('496D00DB33D88356DAE2C344516FD5D699C1F5DE', 'B073C856BA5FD6453B08C04527FFB95DA622FFC1', '1067AFC0B24F69C2050F093DE7F110E4419174F4', 'C438B6CB4131CEBFF6741926B03B7E137641AF4C', '9C2C13C121F71803FC1E697C306C9603B6680303', 'E74B265D5CF4626BF6F360B6379D409AA5D3B8A8', '83F48D641924F90544ED66C701B36BF0E65153C8', 'F3FD3FF45ECC114A665F6C239F6812DE7786A98F', '952AC4BFAB859E9F68762A61D206D690726AF431', 'B726A411FF02675367B07D82059B2E0945C1F3DA', 'D4DFDC63732D33DB14B9E7B3D34D5BF732547F6F', '8F51A4ED9AB3DB6DC5920B06382817C28C2D1A3B', 'E21111899ECFAF1AA5A991D625B2F00BE68024E3', '944CC689671685BC84E5DBBF95A12E0825B85C81', 'A1A83855BF03D91480273FE5C32D1AA33BB77715')\n",
    "\n",
    "# 2017\n",
    "##input_identifiers = ('LE07_L1TP_204033_20170114_20170209_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170319_20170414_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170404_20170430_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170420_20170516_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170506_20170601_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170522_20170617_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170607_20170703_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170623_20170719_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170709_20170804_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170725_20170820_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170810_20170905_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170826_20170921_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170911_20171007_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20170927_20171023_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20171013_20171110_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20171029_20171124_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20171114_20171210_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20171130_20171226_01_T1_sr_P001_NDVI.tif','LE07_L1TP_204033_20171216_20180111_01_T1_sr_P001_NDVI.tif')\n",
    "\n",
    "input_identifiers = ('23CFAEB3EABC76DEB761059E5358AAAA7E6B73C0', '8413BCE5866586CFA8C228F42F4A0857689C20CF', '1559F9C271D8D9133AED47EFB4F253B3E8214701', 'C8D85D9F1D4BFCBC2132F878802D28400E42D35D', 'E8EA192CE196DA08137D8C3D99D5613F51DBB4F6', 'CDED3F2A35002477AC57692830E1D68D066ED4D2', '272816AC6E6E655F0F7247C7C9DA7608B2408893', 'C4F69F8C3AEA1C2C958AB0F97A4D85DCF9CB96CB', 'FED212ED127A33D5B06F95ABD582DAB981C82772', '945E4464682095D6DB964AF430BD53357D54E140', 'FC482A14CE3A63BBDF1CBF591AD9F9E2ECFF58E7', '6B5834E426558BF0F5D167D164C6F1F5EE1D0FFD', '73288D3159115BF7AAEAA049F023340691C0E121', 'D6D4200A3247562D2EA893F23E6B9DB36FA87687', 'A391B46EAEA2CC4E32207B8909B5E991EBFD96E0', 'F3FDC848CD9781ADCF2D85A611ED40CE7E23F454', '6D5DED33A75AF7793F2D62E15692962085730DD9', '62499DA2F0E79F68B86692B468503FD8D9FFDBA2', '07CE2DB5EEE4121950D91543518D4C9A69ED504E')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the NDVI stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references = tuple(['https://catalog.terradue.com/better-ext-02-03-01/search?format=atom&uid={0}'.format(pid) for pid in input_identifiers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/dev/ewf-ext-02-03-01/src/main/app-resources/notebook/libexec\"\n",
    "data_path = \"/workspace/dev/ewf-ext-02-03-01/src/main/app-resources/notebook/libexec/parcel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aux folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.signal\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pdb\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append('/application/notebook/libexec/')\n",
    "from s2_whittaker_helpers import *\n",
    "from whittaker import ws2d, ws2doptv, ws2doptvp\n",
    "import array\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import cioppy\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove contents of a given folder\n",
    "# used to clean a temporary folder\n",
    "def rm_cfolder(folder):\n",
    "    #folder = '/path/to/folder'\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "\n",
    "def get_input_metadata (input_refs):\n",
    "    \n",
    "    # for each product get metadata\n",
    "    Result_Prod = []\n",
    "    \n",
    "    for index,product_ref in enumerate(input_refs):\n",
    "        \n",
    "        # since the search is by identifier \n",
    "        Result_Prod.append(ciop.search(end_point = product_ref,params =[],output_fields='self,identifier,startdate,enclosure,startdate,enddate,wkt,title',creds='{}:{}'.format(ndviIndex['value'],ndviApikey['value']))[0] )\n",
    "    \n",
    "\n",
    "    input_metadata = gpd.GeoDataFrame.from_dict(Result_Prod)\n",
    "\n",
    "    input_metadata['startdate'] = pd.to_datetime(input_metadata['startdate'])\n",
    "    input_metadata['enddate'] = pd.to_datetime(input_metadata['enddate'])\n",
    "    \n",
    "    return input_metadata            \n",
    "\n",
    "            \n",
    "            \n",
    "def get_matrix_list(image_list, mask_value = None):\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        \n",
    "        if mask_value is not None:\n",
    "             product_array = ma.masked_values (product_array, mask_value)\n",
    "        \n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "    return mat_list\n",
    "\n",
    "\n",
    "\n",
    "def get_metadata(filepath):\n",
    "    ds = gdal.Open(filepath)\n",
    "    projection = ds.GetProjection()\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    no_data_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    data_type = ds.GetRasterBand(1).DataType\n",
    "    return projection, geotransform, no_data_value, data_type\n",
    "\n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, mask=None, output_projection=None, output_geotransform=None, no_data_value=None):\n",
    "    \n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    \n",
    "    \n",
    "    if mask is not None and mask is not 0:\n",
    "        # TODO: check if output folder exists\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "        if no_data_value is not None:\n",
    "            output_matrix[mask > 0] = no_data_value\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "    \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    \n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def get_formatted_date(datetime_str):\n",
    "    date = datetime.datetime.strftime(datetime_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    return date\n",
    "\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    \n",
    "    first_date_str = datetime.datetime(year=first_date.year, month=first_date.month, day=first_date.day)\n",
    "    first_date_str = first_date_str + datetime.timedelta(days=0, hours=0, minutes=0, seconds=0)\n",
    "    first_date_str = get_formatted_date(first_date_str)\n",
    "    \n",
    "    last_date_str = datetime.datetime(year=last_date.year, month=last_date.month, day=last_date.day)\n",
    "    last_date_str = last_date_str + datetime.timedelta(days=0, hours=0, minutes=0, seconds=0)\n",
    "    last_date_str = get_formatted_date(last_date_str)\n",
    "    \n",
    "    if (first_date_str == last_date_str):\n",
    "        last_date_str = datetime.datetime(year=last_date.year, month=last_date.month, day=last_date.day)\n",
    "        last_date_str = last_date_str + datetime.timedelta(days=0, hours=23, minutes=59, seconds=59)\n",
    "        last_date_str = get_formatted_date(last_date_str)\n",
    "    \n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (region_of_interest))\n",
    "        \n",
    "        \n",
    "        \n",
    "def ndvi_filter (ts_ndvi_dates, ts_ndvi):\n",
    "    \n",
    "    \n",
    "    dates_a = np.array(ts_ndvi_dates)\n",
    "    ndvi_values_a = np.array(ts_ndvi, dtype='double')\n",
    "    \n",
    "    # remove no values\n",
    "    dates_a = dates_a[ndvi_values_a > -9998]\n",
    "    ndvi_values_a = ndvi_values_a[ndvi_values_a > -9998]\n",
    "    \n",
    "    \n",
    "    dates_jul = [d.strftime('%Y%j') for d in dates_a]\n",
    "\n",
    "    dates_jul2 = [str(a) for a in range(int(str(ts_ndvi_dates[0].year) + '001'), int(str(ts_ndvi_dates[0].year) + '001')+365)]\n",
    "\n",
    "    indate = dates_jul2[4]\n",
    "\n",
    "    ##### create weights\n",
    "    w = np.array((ndvi_values_a!=-9999)*1,dtype='double')\n",
    "\n",
    "    lrange = np.linspace(-1,1,11)\n",
    "\n",
    "    # apply whittaker filter with V-curve\n",
    "    z, lopt = ws2doptv(ndvi_values_a,w,array.array('d',lrange)) # In the original script the function is ws2d_vc, which is defined in modis.py.\n",
    "\n",
    "\n",
    "    ### Temporal interpolation\n",
    "\n",
    "    # little helper objects for managing dates (rtres = raw tem. resolution, stres = desired output temporal resolution)\n",
    "    #dhelper = DateHelper(rawdates=dates, rtres=8, stres=10)\n",
    "\n",
    "    dhelper = DateHelper(rawdates=dates_jul2, rtres=1, stres=15, start=indate)\n",
    "    # daily vector\n",
    "    dvec = dhelper.getDV(nd=-9999)\n",
    "\n",
    "    # target date index \n",
    "    dix = dhelper.getDIX()\n",
    "\n",
    "\n",
    "    # shift observations to midpoint of acquisition (these positions are set to 0 instead of nodata)\n",
    "    for d in dates_jul:\n",
    "        dvec[dhelper.daily.index((fromjulian(d) + datetime.timedelta(1)).strftime('%Y%j'))] = 0\n",
    "\n",
    "    dvec[ dvec != -9999 ] = z\n",
    "\n",
    "    w = np.array((dvec != -9999) * 1,dtype='double')\n",
    "\n",
    "    dvec =  ws2d(dvec,0.0001,w)\n",
    "\n",
    "    z_int = np.array(dvec)[dix]\n",
    "\n",
    "    # plot\n",
    "\n",
    "    xax1 = [fromjulian(x) for x in dates_jul]\n",
    "    xax2 = [fromjulian(x) for x in dhelper.target]\n",
    "\n",
    "    #plt.close()\n",
    "    #plt.figure(figsize=(15,8))\n",
    "    ##plt.ylim(0,1)\n",
    "    #plt.plot(xax1, ndvi_values_a, label='y')\n",
    "    #plt.plot(xax1, z, 'rs', label='z', alpha=0.7)\n",
    "    #plt.plot(xax2, z_int, 'go--', label='z_int', alpha=0.5)\n",
    "\n",
    "\n",
    "   \n",
    "    #plt.xlim((datetime.datetime(dates[0].year, 1, 1, 0, 0), datetime.datetime(dates[0].year, 12, 31, 0, 0)))\n",
    "    #plt.ylim((-1, 1))\n",
    "\n",
    "    #plt.legend()\n",
    "\n",
    "    #plt.savefig('ndvi_' + str(dates[0].year) + '.png', dpi=300)\n",
    "\n",
    "    #plt.show()\n",
    "    \n",
    "    return xax2, z_int\n",
    "\n",
    "\n",
    "\n",
    "def get_formatted_date(datetime_str):\n",
    "    date = datetime.datetime.strftime(datetime_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    " \n",
    "    return date\n",
    "\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    \n",
    "    first_date_str = datetime.datetime(year=first_date.year, month=first_date.month, day=first_date.day)\n",
    "    first_date_str = first_date_str + datetime.timedelta(days=0, hours=0, minutes=0, seconds=0)\n",
    "    first_date_str = get_formatted_date(first_date_str)\n",
    "    \n",
    "    last_date_str = datetime.datetime(year=last_date.year, month=last_date.month, day=last_date.day)\n",
    "    last_date_str = last_date_str + datetime.timedelta(days=0, hours=0, minutes=0, seconds=0)\n",
    "    last_date_str = get_formatted_date(last_date_str)\n",
    "    \n",
    "    if (first_date_str == last_date_str):\n",
    "        last_date_str = datetime.datetime(year=last_date.year, month=last_date.month, day=last_date.day)\n",
    "        last_date_str = last_date_str + datetime.timedelta(days=0, hours=23, minutes=59, seconds=59)\n",
    "        last_date_str = get_formatted_date(last_date_str)\n",
    "\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date_str, last_date_str))\n",
    "        file.write('geometry=%s' % (region_of_interest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folders\n",
    "#if not os.path.isdir(data_path):\n",
    "#    os.mkdir(data_path)\n",
    "\n",
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load metadata from catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'Loading metadata from catalog' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "input_metadata = get_input_metadata (input_references)\n",
    "\n",
    "# order by startdate\n",
    "input_metadata = input_metadata.sort_values(by='startdate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load NDVI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_list = [os.path.join(data_path, file_name.split('/')[-1]) for file_name in input_identifiers]\n",
    "file_list = [os.path.join(data_path, os.path.basename(enclosure).split('?')[0]) for enclosure in input_metadata['enclosure']]\n",
    "\n",
    "img_mat_list = get_matrix_list(file_list, -9999.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = input_metadata['startdate'].tolist()\n",
    "dates = [datetime.datetime.combine(d.date(), d.time()) for d in dates]\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check a NDVI image and a pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "    # image index\n",
    "    img_idx = -1\n",
    "    \n",
    "    # point of interest\n",
    "    point = [10, 10]\n",
    "    point = [0,8]\n",
    "    #point = [0,0]\n",
    "    #point = [17, 13]\n",
    "    #point = [3, 8]\n",
    "    #point = [8, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image\n",
    "if check_results:\n",
    "\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.imshow(img_mat_list[img_idx], cmap='jet', vmin=-1, vmax=1)\n",
    "    \n",
    "    plt.title(dates[img_idx].strftime(\"%d/%m/%Y\"))\n",
    "    \n",
    "    plt.colorbar()\n",
    "    plt.scatter(point[1], point[0], s=100, c='black', marker='*')\n",
    "    \n",
    "    #plt.savefig('ndvi_plot.png', dpi=300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel time series\n",
    "if check_results:\n",
    "    \n",
    "    ndvi_values = [ndvi_img[point[0], point[1]] for ndvi_img in img_mat_list]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.plot(dates, ndvi_values, '-')\n",
    "    plt.plot(dates, ndvi_values, 'o')\n",
    "    \n",
    "    plt.ylim((-1, 1))\n",
    "    #plt.set_xlim([0, 5])\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('ndvi')\n",
    "    #plt.rcParams[\"figure.figsize\"] = (12, 6) # (w, h)\n",
    "\n",
    "    #plt.savefig('ndvi_tm.png', dpi=300)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth and gap fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter a pixel ndvi TM\n",
    "\n",
    "if check_results:\n",
    "    dates_inter, ndvi_inter = ndvi_filter (dates, ndvi_values)\n",
    "\n",
    "if check_results:\n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.ylim(0,1)\n",
    "    plt.plot(dates, ndvi_values, label='y')\n",
    "    #plt.plot(xax1, z, 'rs', label='z', alpha=0.7)\n",
    "    plt.plot(dates_inter, ndvi_inter, 'go--', label='z_int', alpha=0.5)\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('ndvi')\n",
    "   \n",
    "    plt.xlim((datetime.datetime(dates[0].year, 1, 1, 0, 0), datetime.datetime(dates[0].year, 12, 31, 0, 0)))\n",
    "    plt.ylim((-1, 1))\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(max(ndvi_values))\n",
    "    print(min(ndvi_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list of matrices to store interpolated ndvi data\n",
    "ndvi_img_inter = []\n",
    "\n",
    "# number of images -> 365 / 15\n",
    "for i in range(25):\n",
    "    ndvi_img_inter.append(np.full_like(img_mat_list[0].data, -9999.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate ndvi for each pixel\n",
    "dates_inter = []\n",
    "\n",
    "for i in range(img_mat_list[0].shape[0]):\n",
    "    for j in range(img_mat_list[0].shape[1]):\n",
    "        \n",
    "        #print(i,j)\n",
    "        \n",
    "        # get ndvi time series for position i,j\n",
    "        ndvi_tm = [img.data[i,j] for img in img_mat_list]\n",
    "        \n",
    "        # count number of no values\n",
    "        n_novalue = ndvi_tm.count(-9999)\n",
    "        \n",
    "        \n",
    "        if (n_novalue < len(img_mat_list)): # if it's not everything no value\n",
    "            \n",
    "            # swap no value for np.nan\n",
    "            ndvi_tm = [np.nan if x < -9998 else x for x in ndvi_tm]\n",
    "            \n",
    "            # smooth and gap fill\n",
    "            dates_inter, ndvi_inter = ndvi_filter (dates, ndvi_tm)\n",
    "\n",
    "            if max(ndvi_tm) < 0.25: # remove non cultivated pixels I (based on original values)\n",
    "                print('the following pixel will be ignored:')\n",
    "                print(i,j, max(ndvi_tm))\n",
    "            \n",
    "            else:\n",
    "                # swap np.nan for -9999\n",
    "                ndvi_inter[np.isnan(ndvi_inter)] = -9999.0\n",
    "        \n",
    "                # save new time series in position i,j\n",
    "                for idx,ndvi_inter in enumerate(ndvi_inter):\n",
    "                    ndvi_img_inter[idx][i,j] = ndvi_inter\n",
    "\n",
    "\n",
    "\n",
    "# mask -9999 values\n",
    "for idx in range(len(ndvi_img_inter)):\n",
    "    \n",
    "    ndvi_img_inter[idx] = ma.masked_values (ndvi_img_inter[idx], -9999.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "    \n",
    "    #point = [10, 10]\n",
    "    #point = [15, 10]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    img_idx = -1\n",
    "    \n",
    "    plt.imshow(ndvi_img_inter[img_idx], cmap='jet', vmin=-1, vmax=1)\n",
    "    #plt.imshow(mx, cmap='jet', vmin=-1, vmax=1)\n",
    "    \n",
    "    plt.title(dates_inter[img_idx].strftime(\"%d/%m/%Y\"))\n",
    "    \n",
    "    plt.colorbar()\n",
    "    plt.scatter(point[1], point[0], s=100, c='black', marker='*')\n",
    "    \n",
    "    #plt.savefig('ndvi_plot.png', dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(ndvi_img_inter[img_idx].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and remove outliers based on IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image find outliers based on IQR\n",
    "# only for values greater then 2.5 * IQR\n",
    "mat_outliers = []\n",
    "for idx in range(len(ndvi_img_inter)):\n",
    "    \n",
    "    \n",
    "    Q1 = np.percentile(ndvi_img_inter[idx].data[ndvi_img_inter[idx].data > -9998.0], 25)\n",
    "    Q3 = np.percentile(ndvi_img_inter[idx].data[ndvi_img_inter[idx].data > -9998.0], 75)\n",
    "\n",
    "    IQR = Q3-Q1\n",
    "\n",
    "    MinV = Q1 - 2.5 * IQR\n",
    "    MaxV = Q3 + 2.5 * IQR\n",
    "    \n",
    "    if idx == 0:\n",
    "        mat_outliers = ndvi_img_inter[idx].data > MaxV\n",
    "        #mat_outliers = np.logical_or(ndvi_img_inter[idx].data > MaxV, ndvi_img_inter[idx].data < MinV)\n",
    "        \n",
    "    else:\n",
    "        mat_outliers = np.logical_or(mat_outliers, ndvi_img_inter[idx].data > MaxV)\n",
    "        #mat_outliers = np.logical_or(mat_outliers, np.logical_or(ndvi_img_inter[idx].data > MaxV, ndvi_img_inter[idx].data < MinV) )\n",
    "    \n",
    "    \n",
    "#ndvi_img_inter[img_idx].data[mat_outliers]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers from data\n",
    "for idx in range(len(ndvi_img_inter)):\n",
    "    \n",
    "    ndvi_img_inter[idx] = ma.masked_array(ndvi_img_inter[idx], mask=mat_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "    \n",
    "    #point = [10, 10]\n",
    "    #point = [15, 10]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    img_idx = -1\n",
    "    \n",
    "    plt.imshow(ndvi_img_inter[img_idx], cmap='jet', vmin=-1, vmax=1)\n",
    "    #plt.imshow(mx, cmap='jet', vmin=-1, vmax=1)\n",
    "    \n",
    "    plt.title(dates_inter[img_idx].strftime(\"%d/%m/%Y\"))\n",
    "    \n",
    "    plt.colorbar()\n",
    "    plt.scatter(point[1], point[0], s=100, c='black', marker='*')\n",
    "    \n",
    "    #plt.savefig('ndvi_plot.png', dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(ndvi_img_inter[img_idx].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non cultivated pixels II (based on interpolated values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_thr = 0.20 # ndvi threshold \n",
    "\n",
    "mask_mat = np.full(img_mat_list[0].shape, False)\n",
    "\n",
    "for i in range(ndvi_img_inter[0].shape[0]):\n",
    "    for j in range(ndvi_img_inter[0].shape[1]):\n",
    "        \n",
    "        \n",
    "        c_no_values = 0\n",
    "        c_gt_v = 0\n",
    "        \n",
    "        for im in ndvi_img_inter:\n",
    "            \n",
    "            if im[i,j] > ndvi_thr:\n",
    "                    \n",
    "                c_gt_v = c_gt_v + 1\n",
    "                    \n",
    "                #print(im[i,j])\n",
    "                \n",
    "            if im.data[i,j] < -9998:\n",
    "                \n",
    "                c_no_values = c_no_values + 1\n",
    "                    \n",
    "        if c_gt_v == 0 and c_no_values != len(ndvi_img_inter):\n",
    "            mask_mat[i,j] = True\n",
    "            print(i,j)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply mask to all images\n",
    "for idx in range(len(ndvi_img_inter)):\n",
    "    ndvi_img_inter[idx] = ma.masked_array(ndvi_img_inter[idx], mask=mask_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "    \n",
    "    #point = [10, 10]\n",
    "    #point = [15, 10]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    img_idx = -1\n",
    "    \n",
    "    plt.imshow(ndvi_img_inter[img_idx], cmap='jet', vmin=-1, vmax=1)\n",
    "    #plt.imshow(mx, cmap='jet', vmin=-1, vmax=1)\n",
    "    \n",
    "    plt.title(dates_inter[img_idx].strftime(\"%d/%m/%Y\"))\n",
    "    \n",
    "    plt.colorbar()\n",
    "    plt.scatter(point[1], point[0], s=100, c='black', marker='*')\n",
    "    \n",
    "    #plt.savefig('ndvi_plot.png', dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(ndvi_img_inter[img_idx].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check interpolated values for a given pixel\n",
    "if check_results:\n",
    "    \n",
    "    ndvi_values = [ndvi_img[point[0], point[1]] for ndvi_img in ndvi_img_inter]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.plot(dates_inter, ndvi_values, '-')\n",
    "    plt.plot(dates_inter, ndvi_values, 'o')\n",
    "    \n",
    "    \n",
    "    ndvi_values = np.array(ndvi_values)\n",
    "    dates_inter = np.array(dates_inter)\n",
    " \n",
    "    plt.ylim((-1, 1))\n",
    "    #plt.set_xlim([0, 5])\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('ndvi')\n",
    "\n",
    "    #plt.savefig('ndvi_tm.png', dpi=300)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find start and end dates of growing season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Input: ndvi time series and dates\n",
    "# Output: start and end dates and ndvi values of growing season\n",
    "#\n",
    "def find_start_end_date_season(dates_ts, ndvi_ts):\n",
    "    \n",
    "    # max value position \n",
    "    maxp = int(np.where(ndvi_ts == np.amax(ndvi_ts))[0])\n",
    "    \n",
    "    peaks, dic_k = scipy.signal.find_peaks(ndvi_ts, height=-1)\n",
    "    \n",
    "    # index of maximum peak\n",
    "    maxp = peaks[np.where(dic_k['peak_heights'] == np.amax(dic_k['peak_heights']))[0][0]]\n",
    "    \n",
    "    #print(peaks,dic_k)\n",
    "    \n",
    "    #print(len(peaks))\n",
    "   \n",
    "    # find start of season\n",
    "        \n",
    "    # first half\n",
    "    x = [d.timetuple().tm_yday for d in dates_ts[0:maxp+1]]\n",
    "    y = ndvi_ts[0:maxp+1]\n",
    "    \n",
    "\n",
    "    # choose best fit (linear, square, cubic)\n",
    "    r2 = 0\n",
    "    #p1 = None\n",
    "    for d in [1,2]:\n",
    "    \n",
    "        coeffs_aux = np.polyfit(x=x, y=y, deg=d)\n",
    "        p1_aux = np.poly1d(coeffs_aux)\n",
    "\n",
    "        r2_aux = 1 - sum((y-p1_aux(x))**2) / sum((y-np.mean(y))**2)\n",
    "    \n",
    "        if r2_aux > r2:\n",
    "            coeffs = coeffs_aux\n",
    "            p1 = p1_aux\n",
    "            r2 = r2_aux\n",
    "\n",
    "    #if p1 is None:\n",
    "    #    return -9999, -9999, -9999, -9999\n",
    "            \n",
    "    # derivative\n",
    "    p2 = np.polyder(p1)\n",
    "    \n",
    "    i = 0\n",
    "    for vp, vpd, d, ddate in zip(y,p2(x),x,dates_ts):\n",
    "    \n",
    "        #print(d, vpd, vp)\n",
    "        \n",
    "        if i == 0:\n",
    "            start_season_ndvi = vp\n",
    "            start_season_date = ddate\n",
    "    \n",
    "        # if derivative positive and ndvi value positive\n",
    "        # get values and stop search\n",
    "        if vpd > 0 and vp > 0:\n",
    "        \n",
    "            #print(d, vpd, vp)\n",
    "        \n",
    "            start_season_ndvi = vp\n",
    "            start_season_date = ddate\n",
    "        \n",
    "            break\n",
    "            \n",
    "        i = i + 1\n",
    "            \n",
    "    \n",
    "    #print('start date')\n",
    "    #plt.figure()\n",
    "    #plt.plot(x, p1(x))\n",
    "    #plt.plot(x, p2(x))\n",
    "\n",
    "    # END OF SEASON\n",
    "    \n",
    "    x = [d.timetuple().tm_yday for d in dates_ts[maxp:]]\n",
    "    y = ndvi_ts[maxp:]\n",
    "    \n",
    "    \n",
    "    #x_fliped = np.flip(x, axis=None)\n",
    "    #y_fliped = np.flip(y, axis=None)\n",
    "    \n",
    "    x_fliped = x[::-1]\n",
    "    y_fliped = y[::-1]\n",
    "\n",
    "    # choose best fit\n",
    "    r2 = 0\n",
    "    #p1 = None\n",
    "    for d in [1,2]:\n",
    "    \n",
    "        coeffs_aux = np.polyfit(x=x, y=y_fliped, deg=d)\n",
    "        p1_aux = np.poly1d(coeffs_aux)\n",
    "\n",
    "        r2_aux = 1 - sum((y_fliped-p1_aux(x))**2) / sum((y_fliped-np.mean(y_fliped))**2)\n",
    "    \n",
    "        if r2_aux > r2:\n",
    "            coeffs = coeffs_aux\n",
    "            p1 = p1_aux\n",
    "            r2 = r2_aux\n",
    "\n",
    "    # derivative\n",
    "    p2 = np.polyder(p1)\n",
    "    \n",
    "    idx = 0\n",
    "    idx_fliped = 0\n",
    "    for vp, vpd, d, d_f in zip(y_fliped,p2(x),x,x_fliped):\n",
    "    \n",
    "        #print(d, vpd, vp)\n",
    "        \n",
    "        #print(p1(x))\n",
    "        \n",
    "        # if derivative positive and ndvi value positive\n",
    "        # get values and stop search\n",
    "        if vpd > 0 and vp > 0:\n",
    "        \n",
    "            #print(d, vpd, vp)\n",
    "        \n",
    "            d = d_f\n",
    "            \n",
    "            idx_fliped = idx\n",
    "            \n",
    "            break\n",
    "            \n",
    "        idx = idx + 1\n",
    "\n",
    "    idx_end = len(dates_ts) - (idx_fliped+1)\n",
    "        \n",
    "    end_season_date = dates_ts[idx_end]\n",
    "    end_season_ndvi = ndvi_ts[idx_end]\n",
    "\n",
    "    \n",
    "    #plt.plot(x, y, 'o')\n",
    "    #plt.plot(d, vp, 's')\n",
    "    #print('end date')\n",
    "    #plt.figure()\n",
    "    #plt.plot(x, p1(x))\n",
    "    #plt.plot(x, p2(x))\n",
    "    \n",
    "    #print('poly')\n",
    "    #print(p1)\n",
    "    #print('derivative')\n",
    "    #print(p2(x))\n",
    "    #print('r2')\n",
    "\n",
    "\n",
    "    #print(idx_end)\n",
    "    \n",
    "    return start_season_date, start_season_ndvi, end_season_date, end_season_ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check start and end date for a give pixel TS\n",
    "if check_results:\n",
    "    \n",
    "    ndvi_values = [ndvi_img[point[0], point[1]] for ndvi_img in ndvi_img_inter]\n",
    "    \n",
    "    \n",
    "    start_season_date, start_season_ndvi, end_season_date, end_season_ndvi = find_start_end_date_season(dates_inter, ndvi_values)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.plot(dates_inter, ndvi_values, '-')\n",
    "    plt.plot(dates_inter, ndvi_values, 'o')\n",
    "    plt.plot(start_season_date, start_season_ndvi, 's')\n",
    "    plt.plot(end_season_date, end_season_ndvi, 's')\n",
    "    \n",
    "    ndvi_values = np.array(ndvi_values)\n",
    "    dates_inter = np.array(dates_inter)\n",
    "\n",
    "    \n",
    "    #plt.vlines([datetime.datetime(2014, 1, 1, 0, 0), datetime.datetime(2015, 1, 1, 0, 0), datetime.datetime(2016, 1, 1, 0, 0), datetime.datetime(2017, 1, 1, 0, 0), datetime.datetime(2018, 1, 1, 0, 0)], -1, 1, colors='b', linestyle='--')\n",
    "    \n",
    "    #plt.vlines([datetime.datetime(2014, 4, 1, 0, 0), datetime.datetime(2015, 4, 1, 0, 0), datetime.datetime(2016, 4, 1, 0, 0), datetime.datetime(2017, 4, 1, 0, 0)], -1, 1, colors='g', linestyle='--')\n",
    "    #plt.vlines([datetime.datetime(2014, 9, 1, 0, 0), datetime.datetime(2015, 9, 1, 0, 0), datetime.datetime(2016, 9, 1, 0, 0), datetime.datetime(2017, 9, 1, 0, 0)], -1, 1, colors='r', linestyle='--')\n",
    "    \n",
    "    plt.ylim((-1, 1))\n",
    "    #plt.set_xlim([0, 5])\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('ndvi')\n",
    "\n",
    "    #plt.savefig('ndvi_tm.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute start and end dates of growing season for all images\n",
    "\n",
    "start_date_img = np.full_like(ndvi_img_inter[0].data, -9999.0)\n",
    "end_date_img = np.full_like(ndvi_img_inter[0].data, -9999.0)\n",
    "\n",
    "for i in range(ndvi_img_inter[0].shape[0]):\n",
    "    for j in range(ndvi_img_inter[0].shape[1]):\n",
    "        \n",
    "        #print(i,j)\n",
    "        \n",
    "        ndvi_tm = ma.array([img[i,j] for img in ndvi_img_inter])\n",
    "        \n",
    "        if (ndvi_tm.count() > 0):\n",
    "            \n",
    "            #print(i,j)\n",
    "            \n",
    "            start_season_date, start_season_ndvi, end_season_date, end_season_ndvi = find_start_end_date_season(dates_inter, ndvi_tm)\n",
    "            \n",
    "            start_date_img[i,j] = start_season_date.strftime(\"%j\")\n",
    "            end_date_img[i,j] = end_season_date.strftime(\"%j\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check start and end dates of growing season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "    \n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(end_date_img)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check results for a given pixel\n",
    "if check_results:\n",
    "    \n",
    "    ndvi_values = [ndvi_img[point[0], point[1]] for ndvi_img in ndvi_img_inter]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.plot(dates_inter, ndvi_values, '-')\n",
    "    plt.plot(dates_inter, ndvi_values, 'o')\n",
    "    \n",
    "    start_date_px = datetime.datetime.strptime(str(int(start_date_img[point[0], point[1]])), '%Y%j')\n",
    "    end_date_px = datetime.datetime.strptime(str(int(end_date_img[point[0], point[1]])), '%Y%j')\n",
    "    \n",
    "    plt.vlines([start_date_px], -1, 1, colors='g', linestyle='--')\n",
    "    plt.vlines([end_date_px], -1, 1, colors='r', linestyle='--')\n",
    "    \n",
    "    \n",
    "    ndvi_values = np.array(ndvi_values)\n",
    "    dates_inter = np.array(dates_inter)\n",
    "\n",
    "   \n",
    "    plt.ylim((-1, 1))\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('ndvi')\n",
    "\n",
    "    #plt.savefig('ndvi_tm.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndvi_diffs (matrix_img_list):\n",
    "    \n",
    "    # get mask from first image\n",
    "    mask_mat = matrix_img_list[0].mask\n",
    "    \n",
    "    dif_matrix_img_list = []\n",
    "    for i in range(len(matrix_img_list) - 1):\n",
    "        \n",
    "        diff = matrix_img_list[i+1] - matrix_img_list[i]\n",
    "        \n",
    "        diff = ma.masked_array(diff, mask=mask_mat)\n",
    "        \n",
    "        dif_matrix_img_list.append(diff)\n",
    "        \n",
    "    return dif_matrix_img_list\n",
    "        \n",
    "dif_matrix_img_list = get_ndvi_diffs (ndvi_img_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "    \n",
    "    ndvi_values = [ndvi_img[point[0], point[1]] for ndvi_img in dif_matrix_img_list]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.plot(dates_inter[:-1], ndvi_values, '-')\n",
    "    plt.plot(dates_inter[:-1], ndvi_values, 'o')\n",
    "    \n",
    "    plt.ylim((-1, 1))\n",
    "    #plt.set_xlim([0, 5])\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('ndvi dif')\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (12, 6) # (w, h)\n",
    "\n",
    "    #plt.savefig('ndvi_graph.png', dpi=300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative NDVI value for growing season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndvi_cumulative (matrix_img_list):\n",
    "    \n",
    "    cumulative_matrix_img_list = []\n",
    "    \n",
    "    # get mask from first image\n",
    "    mask_mat = matrix_img_list[0].mask\n",
    "    \n",
    "    cum_ndvi = []\n",
    "    for idx,img_ndvi in enumerate(matrix_img_list):\n",
    "        \n",
    "        if idx == 0:\n",
    "            cum_ndvi = img_ndvi\n",
    "        else:\n",
    "            cum_ndvi = cum_ndvi + img_ndvi\n",
    "        \n",
    "        cum_ndvi = ma.masked_array(cum_ndvi, mask=mask_mat)\n",
    "        \n",
    "        cumulative_matrix_img_list.append(cum_ndvi)\n",
    "        \n",
    "    return cumulative_matrix_img_list\n",
    "        \n",
    "cumulative_matrix_img_list = get_ndvi_cumulative (ndvi_img_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "    \n",
    "    ndvi_values = [ndvi_img[point[0], point[1]] for ndvi_img in cumulative_matrix_img_list]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.plot(dates_inter, ndvi_values, '-')\n",
    "    plt.plot(dates_inter, ndvi_values, 'o')\n",
    "    \n",
    "    #plt.ylim((-1, 1))\n",
    "    #plt.set_xlim([0, 5])\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('mg m^-3')\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (12, 6) # (w, h)\n",
    "\n",
    "    #plt.savefig('ndvi_graph.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI peak value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndvi_peak (matrix_img_list):\n",
    "\n",
    "    # get mask from first image\n",
    "    mask_mat = matrix_img_list[0].mask\n",
    "    \n",
    "    peak_ndvi = []\n",
    "    for idx,img_ndvi in enumerate(matrix_img_list):\n",
    "        if idx == 0:\n",
    "            peak_ndvi = img_ndvi\n",
    "        else:\n",
    "            peak_ndvi = np.where(peak_ndvi < img_ndvi, img_ndvi, peak_ndvi)\n",
    "        \n",
    "    peak_ndvi = ma.masked_array(peak_ndvi, mask=mask_mat)\n",
    "        \n",
    "    return peak_ndvi\n",
    "        \n",
    "peak_matrix_img = get_ndvi_peak (ndvi_img_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(peak_matrix_img)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(peak_matrix_img.max())\n",
    "    print(peak_matrix_img.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask -9999 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_img_ma = ma.masked_array(start_date_img, mask = start_date_img < -9998, fill_value=-9999)\n",
    "\n",
    "type(start_date_img_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date_img_ma = ma.masked_array(end_date_img, mask = end_date_img < -9998, fill_value=-9999)\n",
    "\n",
    "type(end_date_img_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dif_matrix_img_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cumulative_matrix_img_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_matrix_img_ma = ma.masked_array(peak_matrix_img, mask = end_date_img < -9998)\n",
    "\n",
    "type(peak_matrix_img_ma[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics per parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[mat.mean() for mat in cumulative_matrix_img_list]\n",
    "\n",
    "col_names = ['start_date', 'end_date', 'smooth_ndvi_avg', 'smooth_ndvi_mode']\n",
    "smooth_ndvi_parcel = pd.DataFrame(columns=col_names)\n",
    "\n",
    "for idx in range(len(dates_inter)):\n",
    "    \n",
    "    ndvi_avg = ndvi_img_inter[idx].mean()\n",
    "    \n",
    "    #ndvi_mode = float(stats.mode(ndvi_img_inter[idx].data[np.logical_not(ndvi_img_inter[idx].mask)].ravel()).mode)\n",
    "    \n",
    "    freq, val = np.histogram(ndvi_img_inter[idx].data[np.logical_not(ndvi_img_inter[idx].mask)].ravel(), bins=40, range=(-1,1))\n",
    "    ndvi_mode = max(val[np.where(freq == np.amax(freq))])\n",
    "    \n",
    "    \n",
    "    smooth_ndvi_parcel = smooth_ndvi_parcel.append({'start_date': dates_inter[idx], 'end_date': dates_inter[idx], 'smooth_ndvi_avg': ndvi_avg, 'smooth_ndvi_mode': ndvi_mode}, ignore_index=True)\n",
    "\n",
    "smooth_ndvi_parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_date_img_ma.mean()\n",
    "\n",
    "col_names = ['start_date', 'end_date', 'start_growing_season_doy', 'start_growing_season_date']\n",
    "start_date_parcel = pd.DataFrame(columns=col_names)\n",
    "dt_doy = int(start_date_img_ma.mean())\n",
    "dt_day_month_str = datetime.datetime.strptime(str(dates_inter[0].year) + str(dt_doy), \"%Y%j\").strftime(\"%d/%b\") # used to get day and month\n",
    "start_date_parcel = start_date_parcel.append({'start_date': dates_inter[0], 'end_date': dates_inter[-1], 'start_growing_season_doy': dt_doy, 'start_growing_season_date': dt_day_month_str}, ignore_index=True)\n",
    "\n",
    "\n",
    "start_date_parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end_date_img_ma.mean()\n",
    "\n",
    "col_names = ['start_date', 'end_date', 'end_growing_season']\n",
    "end_date_parcel = pd.DataFrame(columns=col_names)\n",
    "dt_doy = int(end_date_img_ma.mean())\n",
    "dt_day_month_str = datetime.datetime.strptime(str(dates_inter[0].year) + str(dt_doy), \"%Y%j\").strftime(\"%d/%b\") # used to get day and month\n",
    "end_date_parcel = end_date_parcel.append({'start_date': dates_inter[0], 'end_date': dates_inter[-1], 'end_growing_season': dt_doy, 'end_growing_season_date': dt_day_month_str}, ignore_index=True)\n",
    "\n",
    "end_date_parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[mat.mean() for mat in dif_matrix_img_list]\n",
    "\n",
    "col_names = ['start_date', 'end_date', 'dif_ndvi']\n",
    "dif_ndvi_parcel = pd.DataFrame(columns=col_names)\n",
    "\n",
    "for idx in range(len(dates_inter)-1):\n",
    "    \n",
    "    dif_ndvi_parcel = dif_ndvi_parcel.append({'start_date': dates_inter[idx], 'end_date': dates_inter[idx+1], 'dif_ndvi': dif_matrix_img_list[idx].mean()}, ignore_index=True)\n",
    "\n",
    "dif_ndvi_parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[mat.mean() for mat in cumulative_matrix_img_list]\n",
    "\n",
    "col_names = ['start_date', 'end_date', 'cumulative_ndvi']\n",
    "cumulative_ndvi_parcel = pd.DataFrame(columns=col_names)\n",
    "\n",
    "for idx in range(len(dates_inter)):\n",
    "    \n",
    "    cumulative_ndvi_parcel = cumulative_ndvi_parcel.append({'start_date': dates_inter[0], 'end_date': dates_inter[idx], 'cumulative_ndvi': cumulative_matrix_img_list[idx].mean()}, ignore_index=True)\n",
    "\n",
    "cumulative_ndvi_parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peak_matrix_img_ma.mean()\n",
    "\n",
    "col_names = ['start_date', 'end_date', 'peak_ndvi']\n",
    "peak_ndvi_parcel = pd.DataFrame(columns=col_names)\n",
    "peak_ndvi_parcel = peak_ndvi_parcel.append({'start_date': dates_inter[0], 'end_date': dates_inter[-1], 'peak_ndvi': peak_matrix_img_ma.mean()}, ignore_index=True)\n",
    "\n",
    "peak_ndvi_parcel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metada data\n",
    "projection, geotransform, no_data_value, data_type = get_metadata(file_list[0])\n",
    "\n",
    "first_part = os.path.basename(file_list[0])[0:4]\n",
    "areaOfInterestName = nameOfRegion['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'ndviStats'\n",
    "\n",
    "start_date = dates_inter[0]\n",
    "end_date = dates_inter[-1]\n",
    "\n",
    "excel_output_name = '_'.join([first_part, var_name, areaOfInterestName, start_date.strftime(\"%Y%j\"), end_date.strftime(\"%Y%j\")]) + '.xlsx'\n",
    "\n",
    "excel_output_name = os.path.join(output_folder, excel_output_name)\n",
    "\n",
    "print(excel_output_name)\n",
    "\n",
    "with pd.ExcelWriter(excel_output_name) as writer:  # doctest: +SKIP\n",
    "    start_date_parcel.to_excel(writer, sheet_name='start_growing_season')\n",
    "    end_date_parcel.to_excel(writer, sheet_name='end_growing_season')\n",
    "    smooth_ndvi_parcel.to_excel(writer, sheet_name='smooth_ndvi')\n",
    "    dif_ndvi_parcel.to_excel(writer, sheet_name='dif_ndvi')\n",
    "    cumulative_ndvi_parcel.to_excel(writer, sheet_name='cumulative_ndvi')\n",
    "    peak_ndvi_parcel.to_excel(writer, sheet_name='peak_ndvi')\n",
    "\n",
    "write_properties_file(excel_output_name, start_date, end_date, regionOfInterest['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ndvi differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'difNdvi'\n",
    "\n",
    "for idx in range(len(dif_ndvi_parcel)):\n",
    "    \n",
    "    #print(dif_ndvi_parcel['start_date'][idx])\n",
    "    \n",
    "    start_date = dif_ndvi_parcel['start_date'][idx]\n",
    "    end_date = dif_ndvi_parcel['end_date'][idx]\n",
    "    \n",
    "    dif_matrix_img = dif_matrix_img_list[idx]\n",
    "    \n",
    "    dif_ndvi_img_name = '_'.join([first_part, var_name, areaOfInterestName, start_date.strftime(\"%Y%j\"), end_date.strftime(\"%Y%j\")]) + '.tif'\n",
    "    \n",
    "    dif_ndvi_img_name = os.path.join(output_folder, dif_ndvi_img_name)\n",
    "    \n",
    "    #print(dif_ndvi_img_name)\n",
    "    \n",
    "    write_output_image(dif_ndvi_img_name, dif_matrix_img, 'GTiff', data_type, None, projection, geotransform, no_data_value)\n",
    "    \n",
    "    write_properties_file(dif_ndvi_img_name, start_date, end_date, regionOfInterest['value'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cumulative ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'cumulativeNdvi'\n",
    "\n",
    "for idx in range(len(cumulative_ndvi_parcel)):\n",
    "    \n",
    "    #print(cumulative_ndvi_parcel['start_date'][idx])\n",
    "    \n",
    "    start_date = cumulative_ndvi_parcel['start_date'][idx]\n",
    "    end_date = cumulative_ndvi_parcel['end_date'][idx]\n",
    "    \n",
    "    cum_matrix_img = cumulative_matrix_img_list[idx]\n",
    "    \n",
    "    cum_ndvi_img_name = '_'.join([first_part, var_name, areaOfInterestName, start_date.strftime(\"%Y%j\"), end_date.strftime(\"%Y%j\")]) + '.tif'\n",
    "    \n",
    "    cum_ndvi_img_name = os.path.join(output_folder, cum_ndvi_img_name)\n",
    "    \n",
    "    #print(cum_ndvi_img_name)\n",
    "    \n",
    "    write_output_image(cum_ndvi_img_name, cum_matrix_img, 'GTiff', data_type, None, projection, geotransform, no_data_value)\n",
    "    \n",
    "    write_properties_file(cum_ndvi_img_name, start_date, end_date, regionOfInterest['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Peak value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peak_matrix_img_ma\n",
    "#peak_ndvi_parcel\n",
    "\n",
    "var_name = 'ndviPeak'\n",
    "\n",
    "start_date = peak_ndvi_parcel['start_date'][0]\n",
    "end_date = peak_ndvi_parcel['end_date'][0]\n",
    "\n",
    "peak_ndvi_img_name = '_'.join([first_part, var_name, areaOfInterestName, start_date.strftime(\"%Y%j\"), end_date.strftime(\"%Y%j\")]) + '.tif'\n",
    "    \n",
    "peak_ndvi_img_name = os.path.join(output_folder, peak_ndvi_img_name)\n",
    "    \n",
    "print(peak_ndvi_img_name)\n",
    "\n",
    "write_output_image(peak_ndvi_img_name, peak_matrix_img, 'GTiff', data_type, None, projection, geotransform, no_data_value)\n",
    "\n",
    "write_properties_file(peak_ndvi_img_name, start_date, end_date, regionOfInterest['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### start growing season date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_date_img_ma\n",
    "#start_date_parcel\n",
    "\n",
    "var_name = 'startSeasonNdvi'\n",
    "\n",
    "start_date = start_date_parcel['start_date'][0]\n",
    "end_date = start_date_parcel['end_date'][0]\n",
    "\n",
    "start_date_ndvi_img_name = '_'.join([first_part, var_name, areaOfInterestName, start_date.strftime(\"%Y%j\"), end_date.strftime(\"%Y%j\")]) + '.tif'\n",
    "    \n",
    "start_date_ndvi_img_name = os.path.join(output_folder, start_date_ndvi_img_name)\n",
    "    \n",
    "print(start_date_ndvi_img_name)\n",
    "\n",
    "write_output_image(start_date_ndvi_img_name, start_date_img_ma, 'GTiff', gdal.GDT_Int32, None, projection, geotransform, no_data_value)\n",
    "\n",
    "write_properties_file(start_date_ndvi_img_name, start_date, end_date, regionOfInterest['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### end growing season date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = 'endSeasonNdvi'\n",
    "\n",
    "start_date = end_date_parcel['start_date'][0]\n",
    "end_date = end_date_parcel['end_date'][0]\n",
    "\n",
    "end_date_ndvi_img_name = '_'.join([first_part, var_name, areaOfInterestName, start_date.strftime(\"%Y%j\"), end_date.strftime(\"%Y%j\")]) + '.tif'\n",
    "    \n",
    "end_date_ndvi_img_name = os.path.join(output_folder, end_date_ndvi_img_name)\n",
    "    \n",
    "print(end_date_ndvi_img_name)\n",
    "\n",
    "write_output_image(end_date_ndvi_img_name, end_date_img_ma, 'GTiff', gdal.GDT_Int32, None, projection, geotransform, no_data_value)\n",
    "\n",
    "write_properties_file(end_date_ndvi_img_name, start_date, end_date, regionOfInterest['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove temporay files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cfolder(temp_folder)\n",
    "\n",
    "os.rmdir(temp_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
